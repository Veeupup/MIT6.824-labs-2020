# lab1 MapReduce

[TOC]

## Test

Passed all tests.

![image-20200626162429093](./test-pass.jpg)







## System Design

Master Workflow:

* Master Go online, and there are file names to be processed in the input, traverse all file names, and initialize MapTasks
* Master Server starts, waits for Worker to come online and request tasks
* Assign Map Task to the worker requesting the task
* If completed within the specified time (10s), the MapTask task is completed, otherwise the status of the task is reset and assigned to another requested worker
* Wait for all Map Tasks to complete
* According to user input nReduce, divide the intermediate files generated by Map Task into n files, and initialize n Reduce Tasks
* Assign Reduce Task to the worker requesting the task
* If completed within the specified time (10s), the Reduce Task is completed, otherwise the status of the task is reset and assigned to another requested worker
* Wait for all Reduce Tasks to complete
* Send a message to each worker to quit the job

Worker Workflow:

* When the Worker goes online, it requests tasks from the Master through RPC calls every 1 second. There are four situations:
   * If there is no task, wait
   * Receive the Map Task assigned by the Master, which contains the file name and Map Task ID to be processed by the Map Task. After completing the Map Task, send the intermediate file name to the Master
   * Receive the Reduce Task assigned by the Master, which contains the file name and Reduce Task ID to be processed by the Reduce Task. After completing the Reduce Task, send the intermediate file name to the Master
   * Receive the shutdown signal and exit at this time

## Details && Points

mechanism:

* Master communicates with Worker: go RPC
* Intermediate file storage: json
* Synchronous messaging: go channel
* Lock: sync.Mutex



### Timeout task mechanism

This task requires two issues to be addressed:

1. If a task times out, the task needs to be reassigned to another Worker
2. If a message is received from the original Worker after a long period of time, the original message needs to be discarded.

Solution:

1. Through the `select` mechanism and `time.Wait()`, after each task is assigned to the Worker, start a `goroutine` for timing. If the time exceeds, then modify the status of the task to `IDLE` and wait. assigned, can be assigned again
2. Set a taskID (**similar to a timestamp**) for each task, and tell it to the Worker when assigning the task. This information needs to be carried when sending the completion message. If the current task times out, then the original The taskID increases. Whenever the Master receives a task completion message, it compares the taskID of the current task.
    * If the taskID carried in the message is equal to the taskID of the task, then the task is completed within the specified time.
    * If the taskID carried in the message is less than the taskID of the task, it means that the task has been assigned to a new task, and the message will be discarded at this time



### Request a task

master:

The master has an RPC interface for allocating tasks. Every time there is a request for a task, it needs to determine whether it can start allocating Map tasks. If all Map tasks are completed, then Reduce tasks can be allocated. If all Reduce tasks are completed, then all Reduce tasks can be allocated. Each worker closes



worker:

Each Worker has only one general request task interface. The Worker does not know what work it will do before receiving a reply from the Master. The Master will tell the Worker what it needs to do by specifying the task type and the task ID that needs to be processed in the reply.



### Divide intermediate values into n buckets

After all Map Tasks are completed, the Master is required to organize all the intermediate files generated by the Map into n buckets, and no tasks will be allocated to the outside at this time.

At this time, all intermediate files need to be read and divided into n buckets as equally as possible. At this time, one point needs to be noted, that is, **KVs with the same Key should be assigned to the same reduce task**. At this time, it needs to be When dividing equally, check whether the end of the current equalization contains all the values of the current Key. If not, you need to increase the end value until the current end value is placed in the same bucket.

Then store the kv value in each bucket into a temporary json file, and initialize the reduce task (containing these intermediate file names).



## Run

Since MapReduce loads mr apps dynamically at runtime, the mr app needs to be compiled first and then run the master and worker. Here we take wc app as an example.



```shell
$ go build -buildmode=plugin ../mrapps/wc.go # Build .so file

$ go run mrmaster.go pg-*.txt

$ go run mrworker.go wc.so # Can start one or more worker processes
```
